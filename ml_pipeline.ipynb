{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml_pipeline.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["TxFQTU7wwH6z","28ePEm2TzDLX","1SjowYZNf1cm","M4WBvMQ6zOLg","OyJWGIUyXbeS","Zd2flwegzW1A","4K3BYEqzzcPo","5pVGCiD6QFb3","tedJ6NDxQadI","0t-lM6gfzhCx"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hc60ZxQ6GdDT","colab_type":"code","colab":{}},"source":["import os\n","import cv2\n","import json\n","import random\n","import gc \n","import numpy as np\n","import pandas as pd\n","\n","import sklearn.svm as svm\n","import sklearn.tree as tree\n","import sklearn.ensemble as ensemble\n","import sklearn.neighbors as neighbors\n","import sklearn.naive_bayes as naive_bayes\n","import sklearn.linear_model as linear_model\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import preprocessing as preproc\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score, log_loss, mean_squared_error, mean_absolute_error, roc_curve, auc, confusion_matrix\n","\n","from google.colab import files\n","from google.colab import drive\n","\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9AMTnmq1v-7S","colab_type":"text"},"source":["# Google Colab Setting"]},{"cell_type":"code","metadata":{"id":"V_vMpcWR6fUq","colab_type":"code","outputId":"82428389-8826-4b93-e8d0-86039ed6b6a1","executionInfo":{"status":"ok","timestamp":1558224796517,"user_tz":240,"elapsed":8167,"user":{"displayName":"Jingrui Yang","photoUrl":"","userId":"11484647325252002820"}},"colab":{"base_uri":"https://localhost:8080/","height":188}},"source":["# Accessing Google sheets\n","!pip install --upgrade -q gspread\n","from google.colab import auth\n","auth.authenticate_user()\n","import gspread\n","from oauth2client.client import GoogleCredentials\n","\n","gc = gspread.authorize(GoogleCredentials.get_application_default())\n","\n","worksheet = gc.open('Metadata1').worksheet('Sheet1')\n","\n","# get_all_values gives a list of rows\n","rows_ = worksheet.get_all_values()\n","print(rows_)\n","\n","#rows = pd.read_excel('Metadata.xlsx')\n","# Convert to a DataFrame and render.\n","#import pandas as pd\n","rows = pd.DataFrame.from_records(rows_)\n","print(rows)\n","\n","new_header = rows.iloc[0] #grab the first row for the header\n","rows = rows[1:] #take the data less the header row\n","rows.columns = new_header #set the header row as the df header"],"execution_count":220,"outputs":[{"output_type":"stream","text":["[['Id', '', 'name', 'URL', 'endDate', 'dataSize', 'table', 'image', 'audio', 'video', 'data type', 'text/csv', 'text/json', 'text/tab-separated-values', 'image/bmp', 'image/jpeg', 'image/png', 'image/tiff', 'audio/x-wav', 'audio/x-aiff', 'video/mp4', 'data format', 'columns [index;name;type;...] for type use categorical, numerical, string, integer, dateTime etc', 'augmented dataset URL', 'taskType', 'taskSubType', 'outputType', 'targetIndex', 'targetName', 'rawData (non csv) ', 'rawDataIndex', 'problemDescription', 'preprocessing', 'preprocessing function call', 'featureExtractor', 'featureExtractor function call', 'featureSelector', 'featureSelector function call', 'sklearn', 'xgboost', 'keras', 'tensorflow', 'lightgbm', 'Libraries', 'estimators', 'estimator1', 'estimator1 function call', 'estimator2', 'estimator2 function call', 'estimator3', 'estimator3 function call', 'postprocessing', 'postprocessing function call', 'performanceMetric', 'crossValidationPerformance', 'codeURIRunningTimeSecondsTesting', 'codeURIRunningTimeSecondsTraining', 'WellWrittenCodeDocRating0-5', 'WellWrittenCodeRating0-5', 'codeURI', 'codeYear', 'codeMonth', 'codeAuthor', 'codeCountry', 'GenericUnivariateSelect', 'SelectPercentile', 'SelectKBest', 'SelectFpr', 'SelectFdr', 'SelectFromModel', 'SelectFwe', 'RFE', 'RFECV', 'VarianceThreshold', 'chi2', 'f_classif', 'f_regression', 'mutual_info_classif', 'mutual_info_regression', 'KNeighborsClassifier', 'KNeighborsRegressor', 'SGDClassifier', 'LinearRegression', 'LogisticRegression', 'Ridge', 'BayesianRidge', 'Lasso', 'SGDRegressor', 'DecisionTreeClassifier', 'DecisionTreeRegressor', 'LinearSVC', 'SVC', 'LinearSVR', 'RandomForestClassifier', 'GradientBoostingClassifier', 'RandomForestRegressor', 'GradientBoostingRegressor', 'MLPClassifier', 'XGBClassifier', 'XGBRegressor', 'CNN', 'ResNet'], ['3', 'yz4953, jy2823', 'digit-recognizer', 'https://www.kaggle.com/c/digit-recognizer', '1/7/20 0:00', '15MB', 'True', 'False', 'False', 'False', 'table', 'True', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'csv', '[0; label;categorical;1; pixel0;integer;4; pixel783;integer]', '', 'classification', 'multiclass', 'classLabel', '1', 'Label', 'False', '', 'To recognize a handwritten digit', 'drop features & entries, normalization/scaling, one hot encoding', '', '', '', '', 'none', 'False', 'False', 'True', 'False', 'False', 'keras', 'cnn', 'cnn', 'Sequential()', '', 'RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)', '', '', '', '', 'accuracy', '0.997', '', 'B', '', '', 'https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6', '2017', 'August', 'Yassine Ghouzam', 'France', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'True', 'False'], ['335', 'yz4953,jy2823', 'spooky-author-identification', 'https://www.kaggle.com/c/spooky-author-identification', '12/15/17 23:59', '4.7MB', 'True', 'False', 'False', 'False', 'table', 'True', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'csv', '[0; id;string;1; text;string;2; author;string]', '', 'classification', 'multiclass', 'probabilities, multiLabel', '1 to 3', 'author', 'False', '', 'Share code and discuss insights to identify horror authors from their writings', 'sklearn.model_selection, text pre-processing', '', 'countvectorizer', \"CountVectorizer(min_df=8, max_features=250000, analyzer='char', ngram_range=(1,ngramLength), binary=False,lowercase=True)\", '', 'none', 'True', 'False', 'False', 'False', 'False', 'sklearn', 'logisticregression', 'decisiontreeclassifier/regressor', \"linear_model.LogisticRegression(C=0.01, solver='sag')\", 'clustering', '', '', '', 'csv conversion', '', 'logloss', '0.1271', '', '', '', '', 'https://www.kaggle.com/selfishgene/generating-sentences-one-letter-at-a-time', '2017', 'December', 'Selfish Gene', 'Israel', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'True', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False'], ['534', 'jy2823, yz4953', 'titanic', 'https://www.kaggle.com/c/titanic', '4/7/20 0:00', '59KB', 'True', 'False', 'False', 'False', 'table', 'True', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'csv', '[0; PassengerId;integer;1; Survived;string;2; Pclass;integer;3; Name;string;4; Sex;categorical;5; Age;integer;6; SibSp;integer;7; Parch;integer;8; Ticket;string;9; Fare;real;10; Cabin;string;11; Embarked;categorical]', '', 'classification', 'binary', 'classLabel', '1', 'Survived', 'False', '', 'Predicting if a passenger survived the sinking of Titanic or not', 'data cleaning, data wrangling', '', '', '', '', 'SelectKBest(f_classif, k=10)', 'True', 'False', 'False', 'False', 'False', 'Sklearn', 'randomforestregressor/classifier', 'randomforestregressor/classifier', 'ensemble.RandomForestClassifier(n_estimators=100)', '', '', '', '', '', '', 'accuracy', '0.8676', '', '', '', '', 'https://www.kaggle.com/startupsci/titanic-data-science-solutions', '2017', 'December', 'Manav Sehgal', 'India', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False'], ['555', 'jy2823, yz4953', 'dogs-vs-cats-redux-kernels-edition', 'https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition', '3/2/17 23:59', '814MB', 'False', 'True', 'False', 'False', 'image', 'False', 'False', 'False', 'False', 'True', 'False', 'False', 'False', 'False', 'False', 'jpg', '[]', '', 'classification', 'binary', 'probabilities', '1', 'Label', 'True', '0', 'To recognize pictures of dogs', 'image pre-processing', '', 'convert data to arrays', '', '', 'none', 'False', 'False', 'False', 'True', 'False', 'TensorFlow', 'cnn', 'cnn', 'Sequential()', '', '', '', '', '', '', 'accuracy', '0.79', '', '', '', '', 'https://www.kaggle.com/risingdeveloper/dogs-vs-cats-keras-implementation', '2018', 'December', 'Rising Odegua', 'Nigeria', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'True', 'False']]\n","   0               1    ...    100     101\n","0   Id                  ...    CNN  ResNet\n","1    3  yz4953, jy2823  ...   True   False\n","2  335   yz4953,jy2823  ...  False   False\n","3  534  jy2823, yz4953  ...  False   False\n","4  555  jy2823, yz4953  ...   True   False\n","\n","[5 rows x 102 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xK3MAgppnZC0","colab_type":"code","colab":{}},"source":["# import xlrd\n","# # worksheet = xlrd.open_workbook('Metadata.xlsx').worksheet('Sheet1')\n","\n","# workbook = xlrd.open_workbook('Metadata.xlsx')\n","\n","# worksheet = workbook.sheet_by_index(0)\n","# # get_all_values gives a list of rows\n","# rows_ = worksheet.get_all_values()\n","\n","# #rows = pd.read_excel('Metadata.xlsx')\n","# # Convert to a DataFrame and render.\n","# #import pandas as pd\n","# rows = pd.DataFrame.from_records(rows_)\n","# print(rows)\n","\n","# new_header = rows.iloc[0] #grab the first row for the header\n","# rows = rows[1:] #take the data less the header row\n","# rows.columns = new_header #set the header row as the df header"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Shhl7NnQ6gaG","colab_type":"code","colab":{}},"source":["def alpha_to_number(alpha_key):\n","  return sum([(ord(alpha)-64)*(26**ind) for ind, alpha in enumerate(list(alpha_key)[::-1])]) - 1\n","\n","# Mapping from Metadata sheet column name to readable columns\n","column_key = {'name': 'C', 'columns': 'W', 'estimator_func_call': 'AU', 'target_name': 'AC', 'output_type': 'AA', 'performance_metric': 'BB', 'feature_selector': 'AL', 'data_form': 'V','feature_extractor':'AJ'}\n","column_key = dict(map(lambda kv: (kv[0], alpha_to_number(kv[1])), column_key.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxFQTU7wwH6z","colab_type":"text"},"source":["# Mount at Google Drive"]},{"cell_type":"markdown","metadata":{"id":"wOwYBjH5wMuK","colab_type":"text"},"source":["If cannot read from the file,  please rerun this statement until \"gdrive/My Drive\" appears on the left bar"]},{"cell_type":"code","metadata":{"id":"OJG0sKlxtaSW","colab_type":"code","outputId":"14b4c1cb-ed48-449d-9895-2ec836bc1543","executionInfo":{"status":"ok","timestamp":1558224800172,"user_tz":240,"elapsed":11805,"user":{"displayName":"Jingrui Yang","photoUrl":"","userId":"11484647325252002820"}},"colab":{"base_uri":"https://localhost:8080/","height":0}},"source":["# Mount Google Drive\n","drive.mount('/gdrive')"],"execution_count":223,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hCQ3yt7Ywg0R","colab_type":"text"},"source":["# Metadata Parsing"]},{"cell_type":"code","metadata":{"id":"aWeydbYR6oZ7","colab_type":"code","colab":{}},"source":["def parseMetaData(row_id):\n","  \n","  \n","  metadata['competition_name'] = rows.loc[row_id][column_key['name']]\n","  metadata['estimator'] = rows.loc[row_id][column_key['estimator_func_call']]\n","  metadata['target_column'] = rows.loc[row_id][column_key['target_name']]\n","  metadata['output_type'] = rows.loc[row_id][column_key['output_type']].split(',')\n","  metadata['metric'] = rows.loc[row_id][column_key['performance_metric']]\n","  metadata['feature_selector'] = rows.loc[row_id][column_key['feature_selector']]\n","  metadata['feature_extractor'] = rows.loc[row_id][column_key['feature_extractor']]\n","  metadata['data_form'] = rows.loc[row_id][column_key['data_form']]\n","  columns = rows.loc[row_id][column_key['columns']]\n","\n","  # Parse column information \n","  numeric_columns = []\n","  unwanted_columns = []\n","  categorical_columns = []\n","  columns_data = [x.strip() for x in columns[1:-1].split(';')]\n","  #print(columns_data)\n","  for ind, val in enumerate(columns_data):\n","    if ind%3 == 2:\n","      if (val == \"numeric\" or val == \"integer\" or val == \"real\"):\n","        numeric_columns.append(columns_data[ind-1])\n","      elif val == \"categorical\":\n","        categorical_columns.append(columns_data[ind-1])\n","      elif val == \"unwanted\" or val == \"string\" or val == 'dateTime':\n","        unwanted_columns.append(columns_data[ind-1])\n","    else:\n","      pass \n","  metadata['numeric_columns'] = numeric_columns\n","  metadata['unwanted_columns'] = unwanted_columns\n","  metadata['categorical_columns'] = categorical_columns\n","  \n","  # Remove target from features columns\n","  if metadata['target_column'] in metadata['numeric_columns']:\n","    metadata['numeric_columns'].remove(metadata['target_column'])\n","  if metadata['target_column'] in metadata['categorical_columns']:\n","    metadata['categorical_columns'].remove(metadata['target_column'])\n","  if metadata['target_column'] in metadata['unwanted_columns']:\n","    metadata['unwanted_columns'].remove(metadata['target_column'])\n","  \n","  print(metadata['competition_name'])\n","  print(metadata['numeric_columns'])\n","  print(metadata['categorical_columns'])\n","  print(metadata['unwanted_columns'])\n","  print(metadata['target_column'])\n","  print(metadata['metric'])\n","  print(metadata['feature_selector'])\n","  print(metadata['feature_extractor'])\n","  print(metadata['estimator'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28ePEm2TzDLX","colab_type":"text"},"source":["# Add relevent import"]},{"cell_type":"code","metadata":{"id":"9rRxxUSsjj_D","colab_type":"code","outputId":"aecf1635-3dd5-4e42-8f17-48864a404df5","executionInfo":{"status":"ok","timestamp":1558224800401,"user_tz":240,"elapsed":12015,"user":{"displayName":"Jingrui Yang","photoUrl":"","userId":"11484647325252002820"}},"colab":{"base_uri":"https://localhost:8080/","height":0}},"source":["# Installations\n","import warnings\n","import random\n","from math import exp\n","warnings.filterwarnings('ignore')\n","\n","# Imports\n","# Preprocessing imports\n","import seaborn as sns\n","%matplotlib inline\n","import string\n","import nltk\n","from nltk.stem import SnowballStemmer\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","nltk.download('stopwords')\n","\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical \n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, MaxPooling2D\n","from keras.optimizers import RMSprop\n","from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n","from keras.callbacks import ReduceLROnPlateau\n","import tensorflow as tf\n","import xgboost as xgb\n","from sklearn.naive_bayes import MultinomialNB\n","import scipy\n","import re\n","\n","# Other initializations\n","sns.set(style='white', context='notebook', palette='deep')\n","epochs_completed = 0\n","index_in_epoch = 0"],"execution_count":225,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1SjowYZNf1cm","colab_type":"text"},"source":["# Data Auxiliary\n","\n","**Applied to Digit Recognizer**\n","\n","1.   Data Description:\n","\n","\n","\n","\n","*   Original training data set: 42.0k x 785 (label x 1, pixel x 784)\n","*   Auxiliary training data set: 60.0k x 785 (label x 1, pixel x 784)\n","\n","> Reference: https://www.kaggle.com/krissa10/train-digit-recognition-mnist\n","\n","\n","\n","\n","\n","*   Concat training data set: 102.0k x 785 (label x 1, pixel x 784)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","2.   Accuracy Performance:\n","\n","\n","*   X_train after augmentaion :  0.8656 (training) 0.9783(validation) Running time: 1557084685.2798023s\n","\n","*   X_train combine with X_train_auxiliary after augmentation: 0.9271(training) 0.9893(validation) Running time: 1557088917.688372s\n","\n","We can observe a significant impovement in data training and validation "]},{"cell_type":"code","metadata":{"id":"2iNTDDAhgKPh","colab_type":"code","colab":{}},"source":["def create_auxi(train_df):\n","  print(train_df.shape)\n","  drive.mount('/content/gdrive')\n","  cwd = 'gdrive/My Drive/Introduction to Data Science Spring 2019 Term Project/jy2823_yz4953/digit-recognizer'\n","  aux_dir = cwd + '/auxiliary_data/train_auxiliary.csv'\n","  aux_df = pd.read_csv(aux_dir)\n","  train_df = pd.concat([train_df, aux_df], axis=0)\n","  print(train_df.shape)\n","  return train_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M4WBvMQ6zOLg","colab_type":"text"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"2MMk3DPzDx-H","colab_type":"code","colab":{}},"source":["def preprocessing(train_df):\n","  if metadata['competition_name']=='dogs-vs-cats-redux-kernels-edition':\n","    train_dogs = [train_df+'/dog/{}'.format(i) for i in os.listdir(train_df+'/dog') ]  #get dog images if 'dog' in i\n","    train_cats = [train_df+'/cat/{}'.format(i) for i in os.listdir(train_df+'/cat') ]  #get cat images if 'cat' in i\n","    train_imgs = train_dogs[2000:4000] + train_cats[2000:4000]  # slice the dataset and use 2000 in each class\n","    random.shuffle(train_imgs)  # shuffle it randomly\n","    #Clear list that are useless\n","    del train_dogs\n","    del train_cats\n","    #gc.collect()   #collect garbage to save memory\n","    nrows = 150\n","    ncolumns = 150\n","    channels = 3  #change to 1 if you want to use grayscale image\n","    #get the train and label data\n","    X, y = read_and_process_image(train_imgs,nrows,ncolumns)\n","\n","    import seaborn as sns\n","    del train_imgs\n","    #gc.collect()\n","\n","    #Convert list to numpy array\n","    X = np.array(X)\n","    y = np.array(y)\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=2)\n","\n","    #clear memory\n","    del X\n","    del y\n","    #gc.collect()\n","  \n","  else:  \n","    #get X and y from input data\n","    if metadata['competition_name']=='digit-recognizer':\n","      train_df = create_auxi(train_df)\n","      X = train_df.drop(metadata['target_column'], 1)\n","      y = train_df[metadata['target_column']]\n","      X = X / 255.0\n","      # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n","      X = X.values.reshape(-1,28,28,1)\n","      # Encode labels to one hot vectors\n","      y = to_categorical(y, num_classes = (np.max(y)+1))\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=2)\n","    \n","    elif metadata['competition_name']=='spooky-author-identification':\n","      #test_data = test_df.loc[:,'text'].reset_index(drop=True)\n","      stratifiedCV = model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=1)\n","      trainInds, validInds = next(stratifiedCV.split(train_df['text'], train_df['author']))\n","      X_train = train_df.loc[trainInds,'text'].reset_index(drop=True)\n","      X_test  = train_df.loc[validInds,'text'].reset_index(drop=True)\n","      trainLabel = train_df.loc[trainInds,'author'].reset_index(drop=True)\n","      validLabel = train_df.loc[validInds,'author'].reset_index(drop=True)\n","      yLabelEncoder = preproc.LabelEncoder()\n","      yLabelEncoder.fit(pd.concat((trainLabel,validLabel)))\n","      y_train = yLabelEncoder.transform(trainLabel)\n","      y_test = yLabelEncoder.transform(validLabel)\n","  \n","    else:\n","      X = train_df.drop(metadata['target_column'], 1)\n","      y = train_df[metadata['target_column']]\n","      X = X.filter(metadata['numeric_columns'] + metadata['categorical_columns'])\n","  \n","      # treat missing values\n","      pd.set_option('mode.chained_assignment', None) # used to subside the panda's chain assignment warning\n","      imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n","      for col in metadata['numeric_columns']:\n","        X[[col]] = imp.fit_transform(X[[col]])\n","    \n","      # Categorial transform  \n","      for col in metadata['categorical_columns']:\n","        col_dummies = pd.get_dummies(X[col], dummy_na=True)\n","        X = pd.concat([X, col_dummies], axis=1)\n","      X.drop(metadata['categorical_columns'], axis=1, inplace=True)\n","  \n","      # Feature normalization\n","      X[metadata['numeric_columns']] = preproc.scale(X[metadata['numeric_columns']])\n","\n","      X_train, X_test, y_train, y_test = train_test_split(X, y)\n","  \n","      \n","  return X_train, X_test, y_train, y_test\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OyJWGIUyXbeS","colab_type":"text"},"source":["# Image Preprocessing"]},{"cell_type":"code","metadata":{"id":"rbOE5_lYXiLg","colab_type":"code","colab":{}},"source":["#A function to read and process the images to an acceptable format for our model\n","def read_and_process_image(list_of_images, nrows,ncolumns,):\n","    \"\"\"\n","    Returns two arrays: \n","        X is an array of resized images\n","        y is an array of labels\n","    \"\"\"\n","    X = [] # images\n","    y = [] # labels\n","    \n","    for image in list_of_images:\n","        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC))  #Read the image\n","        #get the labels\n","        if 'dog' in image:\n","            y.append(1)\n","        elif 'cat' in image:\n","            y.append(0)\n","    \n","    return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zd2flwegzW1A","colab_type":"text"},"source":["# Feature Extraction"]},{"cell_type":"code","metadata":{"id":"tlEz3TgMD2bL","colab_type":"code","colab":{}},"source":["def feature_extraction(X_train, X_test, y_train, y_test):\n","  if metadata['competition_name']=='spooky-author-identification':\n","    ngramLength = 5\n","    print('fitting \"CountVectorizer()\" for bag of char %d-grams' %(ngramLength))\n","    BagOfCharsExtractor = CountVectorizer(min_df=8, max_features=250000, \n","                                          analyzer='char', ngram_range=(1,ngramLength), \n","                                          binary=False,lowercase=True)\n","    BagOfCharsExtractor.fit(pd.concat((X_train,X_test)))\n","    X_train_char = BagOfCharsExtractor.transform(X_train)\n","    X_valid_char = BagOfCharsExtractor.transform(X_test)\n","    ngramLength = 2\n","    print('fitting \"CountVectorizer()\" for bag of word %d-grams' %(ngramLength))\n","    BagOfWordsExtractor = CountVectorizer(min_df=5, max_features=250000, \n","                                          analyzer='word', ngram_range=(1,ngramLength), \n","                                          binary=False,lowercase=True)\n","    BagOfWordsExtractor.fit(pd.concat((X_train,X_test)))\n","    X_train_word = BagOfWordsExtractor.transform(X_train)\n","    X_valid_word = BagOfWordsExtractor.transform(X_test)\n","    # combine and scale features \n","    X_train = scipy.sparse.hstack((X_train_word,X_train_char))\n","    X_test = scipy.sparse.hstack((X_valid_word,X_valid_char))\n","    stdScaler = preproc.StandardScaler(with_mean=False)\n","    stdScaler.fit(scipy.sparse.vstack(((X_train,X_test))))\n","    X_train = stdScaler.transform(X_train)\n","    X_test = stdScaler.transform(X_test)\n"," \n","  else:\n","    extractor = eval(metadata['feature_extractor'])\n","    X_train = extractor.fit_transform(X_train, y_train)\n","    X_test = extractor.fit_transform(X_test, y_test)\n"," \n","  return X_train, X_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4K3BYEqzzcPo","colab_type":"text"},"source":["# Feature Selection"]},{"cell_type":"code","metadata":{"id":"oOtDPzvCD5YL","colab_type":"code","colab":{}},"source":["def feature_selection(X_train, X_test, y_train, y_test):  \n","  selector = eval(metadata['feature_selector'])\n","  X_train = selector.fit_transform(X_train, y_train)\n","  X_test = selector.fit_transform(X_test, y_test)\n","  return X_train, X_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5pVGCiD6QFb3","colab_type":"text"},"source":["# **Data Augmentation**"]},{"cell_type":"code","metadata":{"id":"JzqhUSdCQWB4","colab_type":"code","colab":{}},"source":["#for image augmentation\n","def create_datagen():\n","  datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","  return datagen\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tedJ6NDxQadI","colab_type":"text"},"source":["# **Neurual Network**"]},{"cell_type":"code","metadata":{"id":"MoiafwDOQj-k","colab_type":"code","colab":{}},"source":["#for CNN layer setting\n","def CNN1(model):\n","    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n","    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n","    model.add(MaxPool2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n","    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n","    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation = \"relu\"))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(10, activation = \"softmax\"))   \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-vK8zRwZlpI","colab_type":"code","colab":{}},"source":["def CNN2(model):\n","    model.add(Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(128, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(128, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Flatten())\n","    model.add(Dropout(0.5))  #Dropout for regularization\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWUwBhxnMyT-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gITHmtY5Qgr6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0t-lM6gfzhCx","colab_type":"text"},"source":["# Estimation"]},{"cell_type":"markdown","metadata":{"id":"MRx3WbLmQCdo","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"0U32siwMD8WF","colab_type":"code","colab":{}},"source":["def estimation(X_train, X_test, y_train, y_test): \n","  \n","    start = time.time() \n"," \n","    model = eval(metadata['estimator'])\n","   \n","  ######################### Keras&CNN: digit ######################### \n","    if metadata['competition_name']=='digit-recognizer':   \n","      CNN1(model)\n","      # Define the optimizer\n","      optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","      # Compile the model\n","      model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","      # Set a learning rate annealer\n","      learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)   \n","      epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n","      batch_size = 86\n","      # With data augmentation to prevent overfitting (accuracy 0.99286)#####################Using Data Augmentation\n","      datagen = create_datagen()\n","      datagen.fit(X_train)\n","      # Fit the model\n","      history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n","                              epochs = epochs, validation_data = (X_test,y_test),\n","                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n","                              , callbacks=[learning_rate_reduction])  \n","  ######################### Keras&CNN: digit #########################\n","  \n","  \n","  ####################### Keras&CNN: Dog vs Cat ####################### \n","    elif metadata['competition_name']=='dogs-vs-cats-redux-kernels-edition':\n","      ntrain = len(X_train)\n","      ntest = len(X_test)\n","      batch_size = 32 \n","      CNN2(model)\n","      model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['acc'])\n","      #hist=model.fit(X_train,y_train,epochs=64,batch_size=batch_size,validation_data=(X_test,y_test))\n","  \n","      #train_datagen,val_datagen=create_datagen2()\n","      train_datagen=create_datagen()\n","      train_datagen.fit(X_train)\n","      #val_datagen.fit(X_test)\n","      #train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n","      #val_generator = val_datagen.flow(X_test, y_test, batch_size=batch_size)\n","      history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=batch_size),\n","                              steps_per_epoch=ntrain // batch_size,\n","                              epochs=64,\n","                              validation_data=(X_test,y_test),\n","                              validation_steps=ntest // batch_size)\n","\n","  ####################### Keras&CNN: Dog vs Cat #######################\n","   \n","    else:\n","      model.fit(X_train, y_train)\n","      predict = model.predict(X_test)\n","      if metadata['metric'] == \"rmse\":  \n","        error = np.sqrt(mean_squared_error(y_test, predict))\n","      elif metadata['metric'] == \"accuracy\":\n","        error = accuracy_score(y_test, predict)\n","      elif metadata['metric'] == \"auc\":\n","        fpr, tpr, _ = roc_curve(y_test, predict)\n","        error = auc(fpr, tpr)\n","      elif metadata['metric'] == \"logloss\":\n","        proba = model.predict_proba(X_test)\n","        error = log_loss(y_test, proba)\n","      print(error)\n","  \n","    #print running time\n","    end = time.time()   \n","    print(\"Running time is:\"+str(end-start) + 's')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VstUncpAzsDv","colab_type":"text"},"source":["# Running"]},{"cell_type":"markdown","metadata":{"id":"TRjIN5snGRN6","colab_type":"text"},"source":["Please refer to different training and testing dataset.\n"]},{"cell_type":"code","metadata":{"id":"vMfNxyyyECzK","colab_type":"code","outputId":"0629d900-4015-4ceb-a196-bd84b2ad18bd","executionInfo":{"status":"ok","timestamp":1558228593680,"user_tz":240,"elapsed":3751436,"user":{"displayName":"Jingrui Yang","photoUrl":"","userId":"11484647325252002820"}},"colab":{"base_uri":"https://localhost:8080/","height":4351}},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","drive.mount('/content/gdrive')\n","\n","row_ids = [1,2,3,4] #3digit,534titanic,335author,555dog-vs-cat\n","metadata={}\n","\n","#Set current working directory\n","cwd = 'gdrive/My Drive/Introduction to Data Science Spring 2019 Term Project/jy2823_yz4953/'\n","\n","for row_id in row_ids:\n","  metadata.clear()\n","  print(\"************************************************************\")  \n","  parseMetaData(row_id)\n","  if metadata['competition_name']=='dogs-vs-cats-redux-kernels-edition':\n","    train_df =cwd+metadata['competition_name'] + '/raw data'\n","  else:  \n","    competition_dir = cwd + metadata['competition_name'] + '/data/train.'+metadata['data_form']\n","    #read data for different types\n","    if metadata['data_form']=='csv':\n","      train_df = pd.read_csv(competition_dir)\n","\n","  X_train, X_test, y_train, y_test = preprocessing(train_df)\n","  if metadata['feature_selector'].lower() != 'none':\n","     X_train, X_test, y_train, y_test = feature_selection(X_train, X_test, y_train, y_test)\n","  if metadata['feature_extractor']:\n","     X_train, X_test, y_train, y_test = feature_extraction(X_train, X_test, y_train, y_test)    \n","  estimation(X_train, X_test, y_train, y_test)\n","  print(\"************************************************************\")\n","#   X_train, X_test, y_train, y_test = preprocessing(train_df)\n","#   if metadata['feature_selector'].lower() != 'none':\n","#      X_train, X_test, y_train, y_test = feature_selection(X_train, X_test, y_train, y_test)\n","#   if metadata['feature_extractor'].lower() !='none':\n","#     X_train, X_test, y_train, y_test = feature_extraction(X_train, X_test, y_train, y_test)    \n","#   estimation(X_train, X_test, y_train, y_test)\n","#   print(\"************************************************************\")"],"execution_count":236,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","************************************************************\n","digit-recognizer\n","['pixel0', 'pixel783']\n","['label']\n","[]\n","Label\n","accuracy\n","none\n","\n","Sequential()\n","(42000, 785)\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","(102000, 785)\n","Epoch 1/30\n"," - 23s - loss: 0.2414 - acc: 0.9251 - val_loss: 0.0398 - val_acc: 0.9876\n","Epoch 2/30\n"," - 21s - loss: 0.0811 - acc: 0.9761 - val_loss: 0.0277 - val_acc: 0.9908\n","Epoch 3/30\n"," - 21s - loss: 0.0647 - acc: 0.9816 - val_loss: 0.0299 - val_acc: 0.9921\n","Epoch 4/30\n"," - 23s - loss: 0.0603 - acc: 0.9831 - val_loss: 0.0242 - val_acc: 0.9929\n","Epoch 5/30\n"," - 22s - loss: 0.0584 - acc: 0.9837 - val_loss: 0.0384 - val_acc: 0.9916\n","Epoch 6/30\n"," - 21s - loss: 0.0607 - acc: 0.9836 - val_loss: 0.0281 - val_acc: 0.9928\n","Epoch 7/30\n"," - 20s - loss: 0.0625 - acc: 0.9838 - val_loss: 0.0234 - val_acc: 0.9933\n","Epoch 8/30\n"," - 22s - loss: 0.0655 - acc: 0.9828 - val_loss: 0.0303 - val_acc: 0.9923\n","Epoch 9/30\n"," - 20s - loss: 0.0661 - acc: 0.9826 - val_loss: 0.0375 - val_acc: 0.9925\n","Epoch 10/30\n"," - 20s - loss: 0.0712 - acc: 0.9816 - val_loss: 0.0315 - val_acc: 0.9915\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 11/30\n"," - 21s - loss: 0.0513 - acc: 0.9865 - val_loss: 0.0235 - val_acc: 0.9937\n","Epoch 12/30\n"," - 22s - loss: 0.0497 - acc: 0.9867 - val_loss: 0.0244 - val_acc: 0.9941\n","Epoch 13/30\n"," - 20s - loss: 0.0532 - acc: 0.9862 - val_loss: 0.0256 - val_acc: 0.9936\n","Epoch 14/30\n"," - 21s - loss: 0.0519 - acc: 0.9863 - val_loss: 0.0247 - val_acc: 0.9932\n","Epoch 15/30\n"," - 20s - loss: 0.0562 - acc: 0.9852 - val_loss: 0.0408 - val_acc: 0.9920\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 16/30\n"," - 22s - loss: 0.0435 - acc: 0.9881 - val_loss: 0.0364 - val_acc: 0.9925\n","Epoch 17/30\n"," - 20s - loss: 0.0451 - acc: 0.9881 - val_loss: 0.0309 - val_acc: 0.9933\n","Epoch 18/30\n"," - 21s - loss: 0.0426 - acc: 0.9881 - val_loss: 0.0317 - val_acc: 0.9940\n","\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 19/30\n"," - 21s - loss: 0.0386 - acc: 0.9896 - val_loss: 0.0255 - val_acc: 0.9942\n","Epoch 20/30\n"," - 23s - loss: 0.0370 - acc: 0.9895 - val_loss: 0.0344 - val_acc: 0.9925\n","Epoch 21/30\n"," - 20s - loss: 0.0395 - acc: 0.9892 - val_loss: 0.0363 - val_acc: 0.9931\n","\n","Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Epoch 22/30\n"," - 20s - loss: 0.0352 - acc: 0.9901 - val_loss: 0.0333 - val_acc: 0.9937\n","Epoch 23/30\n"," - 21s - loss: 0.0371 - acc: 0.9897 - val_loss: 0.0355 - val_acc: 0.9936\n","Epoch 24/30\n"," - 21s - loss: 0.0342 - acc: 0.9903 - val_loss: 0.0298 - val_acc: 0.9935\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","Epoch 25/30\n"," - 20s - loss: 0.0343 - acc: 0.9907 - val_loss: 0.0342 - val_acc: 0.9940\n","Epoch 26/30\n"," - 20s - loss: 0.0332 - acc: 0.9906 - val_loss: 0.0320 - val_acc: 0.9939\n","Epoch 27/30\n"," - 22s - loss: 0.0334 - acc: 0.9908 - val_loss: 0.0318 - val_acc: 0.9942\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","Epoch 28/30\n"," - 21s - loss: 0.0331 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9938\n","Epoch 29/30\n"," - 20s - loss: 0.0310 - acc: 0.9914 - val_loss: 0.0322 - val_acc: 0.9942\n","Epoch 30/30\n"," - 20s - loss: 0.0312 - acc: 0.9910 - val_loss: 0.0330 - val_acc: 0.9941\n","\n","Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n","Running time is:632.6730616092682s\n","************************************************************\n","************************************************************\n","spooky-author-identification\n","[]\n","[]\n","['id', 'text']\n","author\n","logloss\n","none\n","CountVectorizer(min_df=8, max_features=250000, analyzer='char', ngram_range=(1,ngramLength), binary=False,lowercase=True)\n","linear_model.LogisticRegression(C=0.01, solver='sag')\n","fitting \"CountVectorizer()\" for bag of char 5-grams\n","fitting \"CountVectorizer()\" for bag of word 2-grams\n","0.36069434005263107\n","Running time is:44.73254036903381s\n","************************************************************\n","************************************************************\n","titanic\n","['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n","['Sex', 'Embarked']\n","['Name', 'Ticket', 'Cabin']\n","Survived\n","accuracy\n","SelectKBest(f_classif, k=10)\n","\n","ensemble.RandomForestClassifier(n_estimators=100)\n","0.5067264573991032\n","Running time is:0.10875153541564941s\n","************************************************************\n","************************************************************\n","dogs-vs-cats-redux-kernels-edition\n","[]\n","[]\n","[]\n","Label\n","accuracy\n","none\n","\n","Sequential()\n","Epoch 1/64\n","83/83 [==============================] - 13s 152ms/step - loss: 0.0275 - acc: 0.9970 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 2/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 3/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 4/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 5/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 6/64\n","83/83 [==============================] - 12s 143ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 7/64\n","83/83 [==============================] - 13s 152ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 8/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 9/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 10/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 11/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 12/64\n","83/83 [==============================] - 12s 147ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 13/64\n","83/83 [==============================] - 12s 146ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 14/64\n","83/83 [==============================] - 12s 147ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 15/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 16/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 17/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 18/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 19/64\n","83/83 [==============================] - 13s 157ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 20/64\n","83/83 [==============================] - 13s 152ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 21/64\n","83/83 [==============================] - 12s 141ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 22/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 23/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 24/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 25/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 26/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 27/64\n","83/83 [==============================] - 13s 155ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 28/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 29/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 30/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 31/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 32/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 33/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 34/64\n","83/83 [==============================] - 13s 155ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 35/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 36/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 37/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 38/64\n","83/83 [==============================] - 12s 148ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 39/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 40/64\n","83/83 [==============================] - 12s 140ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 41/64\n","83/83 [==============================] - 13s 155ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 42/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 43/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 44/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 45/64\n","83/83 [==============================] - 12s 150ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 46/64\n","83/83 [==============================] - 12s 145ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 47/64\n","83/83 [==============================] - 12s 145ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 48/64\n","83/83 [==============================] - 12s 149ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 49/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 50/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 51/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 52/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 53/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 54/64\n","83/83 [==============================] - 12s 148ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 55/64\n","83/83 [==============================] - 12s 146ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 56/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 57/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 58/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 59/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 60/64\n","83/83 [==============================] - 12s 139ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 61/64\n","83/83 [==============================] - 13s 151ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 62/64\n","83/83 [==============================] - 12s 144ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 63/64\n","83/83 [==============================] - 11s 138ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Epoch 64/64\n","83/83 [==============================] - 12s 148ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n","Running time is:755.6144251823425s\n","************************************************************\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UhQK7oR56UDJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}